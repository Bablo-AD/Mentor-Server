{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Handler building R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from brain import brain_api,message_history\n",
    "from data import HabiticaData,GoogleKeepData\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = GoogleKeepData(os.environ.get('KEEP_EMAIL'),os.environ.get('KEEP_PASSWORD'))\n",
    "keep = keep.execute(num_days=3)\n",
    "habitica = HabiticaData(os.environ.get('HABITICA_USER_ID'),os.environ.get('HABITICA_API_KEY'))\n",
    "habitica = habitica.execute(num_days=3)\n",
    "keep,habitica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TARGET_DATE = datetime.today()\n",
    "NUM_DAYS = 5\n",
    "load_user = message_history()\n",
    "load_user.load_mentorship(habitica,keep,TARGET_DATE,NUM_DAYS)\n",
    "load_user.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = brain_api(os.environ.get('OPENAI_API_KEY'))\n",
    "gpt_model.get_completion(load_user,temperature=0.5,update_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.messages = [{'role': 'user',\n",
    "  'content': 'Hey now you are my partner who criticizes me and helps me grow. Here I provide you my habits and journal entries from the past 5 days till 2023-06-13 19:31:52.885669'},\n",
    " {'role': 'user',\n",
    "  'content': 'My habits: [\\'Task Name                Date\\', \\'Oil hair 2023-06-10 03:55:47\\', \\'Sunday grooming list 2023-06-10 03:55:47\\', \\'Gratitude journal 2023-06-10 17:01:52\\', \\'Toilet 2023-06-10 17:01:53\\', \\'Exercise 2023-06-10 17:01:54\\', \\'Sunlight 2023-06-10 17:01:56\\', \\'Water the plants 2023-06-10 17:02:01\\', \\'Turn on focus mode 2023-06-10 17:02:06\\', \\'Worship god 2023-06-10 17:02:07\\', \\'Podcast 2023-06-10 17:02:08\\', \\'Hindi 2023-06-10 17:02:11\\', \\'Read book 2023-06-10 17:02:12\\', \\'Study for 6 to 8 2023-06-10 17:02:18\\', \\'External perspective thinking 2023-06-10 17:02:19\\', \\'No time wastage 2023-06-10 17:02:25\\', \\'Use social media 2023-06-10 17:02:29\\', \\'Journal 2023-06-10 17:02:30\\', \\'Talk with Master mind 2023-06-10 17:02:33\\', \\'10hrs sleep 2023-06-10 17:02:39\\', \\'Sunday grooming list 2023-06-12 16:35:37\\', \\'Shampoo 2023-06-12 16:35:37\\', \\'Oil hair 2023-06-12 16:35:37\\', \\'Gratitude journal 2023-06-12 16:40:11\\', \\'Toilet 2023-06-12 16:40:17\\', \\'Exercise 2023-06-12 16:40:19\\', \\'Sunlight 2023-06-12 16:40:21\\', \\'Water the plants 2023-06-12 16:40:22\\', \\'Worship god 2023-06-12 16:40:26\\', \\'Read book 2023-06-12 16:40:29\\', \\'Study for 6 to 8 2023-06-12 16:40:30\\', \\'Post on twitter 2023-06-12 16:40:40\\', \\'No time wastage 2023-06-12 16:40:42\\', \\'Journal 2023-06-12 17:28:15\\', \\'Talk with Master mind 2023-06-12 17:28:21\\']. My journal: [\"12.06.23 So today i woke up at 8:15ish brushed my teeth wrote gratitude my mind was fresh and clear Gone upstairs to get some sunlight. Came to poop the poop was light yellow. Exercised with the home workout app it was a good workout i am noticing that i am kind off breathing through my mouth these days it is bad i would like to fix it. Then i took bath with new shampoo from homeopathy thing i liked it next i went to post office to post some books that makes some kids learn. Next I came home turned on AC started to go over the email sent by the non-trivial got some interested about the 8000 hours thing then everything collapsed i relapsed and things went haywire i took some powernap then some thinking to get back track and gone to ibaco ice cream to get my mind to actually post in order to stay motivated and building stuff. The internet was less but i did my best then i played with a cockroach it was big and scared me a ton. Anyway the things went wrong are \\\\n- I didn\\'t stay in the place where i would be productive\\\\n- I should have made a decision to walk instead of fapping up\\\\nAnyway i did it so now the only plan is to get away from this is to get up and do things on my purpose like have rigid plans to work on so for tomorrow the iteration 2 starts the main important stuff about iteration 2 is integrating Bablo and Mentor. First integrate Bablo and Mentor app and make them work together.THIS IS MY PURPOSE AND I DO IT.t\", \\'10.6.23 Today I woke up brushed teeth done some walking passed of by light yellow poop. Done some exercise by walk and gone to my bros house to play some cards and stuff and i am not gonna discuss about it i am gonna discuss about the shape work that i have been producing so \\\\n\\']'},\n",
    " {'role': 'assistant',\n",
    "  'content': \"Thank you for sharing your habits and journal entries with me. It's great to see that you have a variety of positive habits such as gratitude journaling, exercising, and spending time in sunlight. \\n\\nHowever, I noticed that on June 12th, you had a setback and struggled to stay productive. It's important to acknowledge these moments and reflect on what led to them, as you have done in your journal entry. It's also great to see that you have a plan to improve and have set a specific goal for iteration 2. \\n\\nOne suggestion I have is to prioritize your habits and tasks each day. It can be overwhelming to try to do everything on your list, so consider focusing on the most important ones first. Also, try to eliminate any distractions or factors that may lead to unproductive behavior. \\n\\nOverall, keep up the good work and continue to reflect on your progress and areas for improvement.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.messages = [load_user.messages[-1]]\n",
    "load_user.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.load_python_fear()\n",
    "load_user.load_query()\n",
    "load_user.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_user.add_user(f'Hey i would like to watch youtube can you give me a search query that fits my goal')\n",
    "gpt_model.get_completion(load_user,temperature=0.5,update_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.messages[-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r'\"([^\"]*)\"', load_user.messages[-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import google.auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import re\n",
    "from brain import brain_api,message_history\n",
    "\n",
    "class youtube_recommender:\n",
    "  def __init__(self):\n",
    "    # Set up the YouTube Data API client\n",
    "    self.temperature = 0.3\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    DEVELOPER_KEY = os.environ.get('YOUTUBE_API_KEY') # Replace with your own API key\n",
    "    self.youtube = build(api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "    self.gpt_model = brain_api(os.environ.get('OPENAI_API_KEY'))\n",
    "\n",
    "  # Makes query\n",
    "  def make_query(self,message_history,goal=''):\n",
    "    message_history.load_python_fear()\n",
    "    message_history.load_query(goal)\n",
    "    self.gpt_model.get_completion(load_user,temperature=self.temperature,update_history=True)\n",
    "    self.query = re.findall(r'\"([^\"]*)\"', message_history.messages[-1]['content'])\n",
    "    return self.query\n",
    "\n",
    "  def youtube_searcher(self):\n",
    "    search_response = self.youtube.search().list(\n",
    "    q=self.query,\n",
    "    type=\"video\",\n",
    "    part=\"id,snippet\",\n",
    "    maxResults=10\n",
    "    ).execute()\n",
    "    videos = []\n",
    "    for search_result in search_response.get(\"items\", []):\n",
    "        video_id = search_result[\"id\"][\"videoId\"]\n",
    "        video_title = search_result[\"snippet\"][\"title\"]\n",
    "        video_description = search_result[\"snippet\"][\"description\"]\n",
    "        video_tags = search_result[\"snippet\"][\"tags\"] if \"tags\" in search_result[\"snippet\"] else []\n",
    "        videos.append((video_title,video_id))\n",
    "    self.youtube_videos = videos\n",
    "    return self.youtube_videos\n",
    "\n",
    "  # We will commenting it for now we will work on it later\n",
    "  # def AI_filter(self):\n",
    "  #   completion = openai.ChatCompletion.create(\n",
    "  #   model=\"gpt-3.5-turbo\",\n",
    "  #   messages=[\n",
    "  #     {\"role\": \"user\",\"content\":f\"User journal: {self.short_journal}. Now i need you to help the user by selecting three youtube videos in the interest of {self.aspiration} from this list  {[x[0] for x in self.youtube_videos]}\"}\n",
    "\n",
    "  #     ],\n",
    "  #     temperature=0)\n",
    "  #   return completion.choices[0].message['content']\n",
    "    \n",
    "  \n",
    "  # def refine_completion(self,msg):\n",
    "  #   video_titles = re.findall(r'\\d+\\. (.+)', msg)\n",
    "  #   result_list = {\"completion\":msg}\n",
    "    \n",
    "  #   for title in video_titles:\n",
    "  #       for video in self.youtube_videos:\n",
    "  #         #second.append(video[0].strip(\"'\"))\n",
    "  #         if title.strip(\"'\") == video[0].strip(\"'\"):\n",
    "              \n",
    "  #           result_list[title]= video[1]\n",
    "  #           print(title,video)\n",
    "    \n",
    "  #   return result_list\n",
    "\n",
    "  def execute(self,message_history,goal=''):\n",
    "    self.make_query(message_history,goal)\n",
    "    return self.youtube_searcher()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend = youtube_recommender()\n",
    "recommend.make_query(load_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend.youtube_searcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_user.load_python_fear()\n",
    "recommend.gpt_model.get_completion(load_user,temperature=0.3,message=f'Hey i would be passing some results of the query I want you to choose videos that benefit the user')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube recommendation R&D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommendation_system import youtube_recommender\n",
    "from dotenv import load_dotenv\n",
    "from brain import brain_api\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "gpt_model = brain_api(os.environ.get(\"OPENAI_API_KEY\"))\n",
    "recommender = youtube_recommender(gpt_model = gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender.query = ['Productivity tips and hacks', 'Morning routine for success', 'Overcoming challenges and staying motivated', 'Personal development and self-improvement', 'Time management strategies', 'Mindfulness and meditation practices', 'Building healthy habits and routines', 'Motivational speeches and inspirational videos', 'Entrepreneurship and business success stories', 'Technology and app development tutorials']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommends = {}\n",
    "for i in recommender.query:\n",
    "    recommends[i] = recommender.youtube_searcher(query=i)\n",
    "recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommends['Productivity tips and hacks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_response = recommender.youtube.search().list(\n",
    "    q='Productivity tips and hacks',\n",
    "    type=\"video\",\n",
    "    part=\"id,snippet,\n",
    "    maxResults=5,\n",
    "    order='rating',\n",
    "    ).execute()\n",
    "search_response.get(\"items\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "YouTubeTranscriptApi.get_transcript(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"nakku\"  # supply your API key however you choose\n",
    "\n",
    "completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=[{\"role\": \"user\", \"content\": \"Hello world\"}])\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant Openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.beta.threads.delete(\"thread_ZmeQWVdT7fz8DuXvoLLJuPyn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread_id,\n",
    "    role=\"user\",\n",
    "    content=\"Tomorrow is my exam and i didn't prepare anything what should i do?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=\"asst_jRbfW9QFoxtbP9XR5W1QUgMr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread_id,\n",
    "  run_id=run.id\n",
    ")\n",
    "run.status, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread_id,order=\"desc\",limit=1)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.data[-1].content[-1].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.required_action:\n",
    "    for i in run.required_action.submit_tool_outputs.tool_calls:\n",
    "        print(i.function.name,i.function.arguments)\n",
    "        print(type(i.function.name),type(i.function.arguments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_step = client.beta.threads.runs.steps.retrieve(\n",
    "    thread_id=thread_id,\n",
    "    run_id=run.id,\n",
    "    step_id=\"step_abc123\"\n",
    ")\n",
    "run_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id='thread_7h1V8SoNHQDcQNli9PMkd9RE'\n",
    ")\n",
    "messages.data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "token = c\n",
    "org = \"org-RSXPRFppcuEboCAYlw4sjE5c\"\n",
    "url = \"https://api.openai.com/v1/threads\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {token}\",  \n",
    "    \"OpenAI-Beta\": \"assistants=v1\"\n",
    "}\n",
    "params = {\"limit\": 10}\n",
    "resp = req.get(url, headers=headers, params=params)\n",
    "print(resp.json())\n",
    "ids = [t['id'] for t in resp.json()['data']]\n",
    "\n",
    "while len(ids) > 0:\n",
    "    for tid in ids:\n",
    "        client.beta.threads.delete(tid)\n",
    "        time.sleep(1)\n",
    "    resp = req.get(url, headers=headers, params=params)\n",
    "    ids = [t['id'] for t in resp.json()['data']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "run = client.beta.threads.runs.cancel(\n",
    "  thread_id=\"thread_qLQtIgSxIuEXWJstaTHA97nV\",\n",
    "  run_id=\"run_Es7ka9oE5gypykqKvz6V5U78\"\n",
    ")\n",
    "print(run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=\"thread_qLQtIgSxIuEXWJstaTHA97nV\",order=\"desc\",limit=2)\n",
    "messages.data[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api.recommendation_system import youtube_recommender\n",
    "yt = youtube_recommender()\n",
    "yt.youtube_searcher({},query='Productivity tips and hacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(r\"C:\\Users\\prasannan-robots\\Desktop\\Mentor\\Mentor-Server\\data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)sssss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\"This is a document\", \"This is another document\"],\n",
    "    metadatas=[{\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    ids=[\"id1\", \"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\"Robots are cool\", \"Robots can create documents\"],\n",
    "    metadatas=[{\"source\": \"my_source\"}, {\"source\": \"my_source\"}],\n",
    "    ids=[\"id3\", \"id4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"Document\"],\n",
    "    n_results=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.readers.file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstorage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleChatStore\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatMemoryBuffer\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFReader\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#from llama_hub.youtube_transcript import YoutubeTranscriptReader\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# create client and a new collection\u001b[39;00m\n\u001b[0;32m     17\u001b[0m chroma_client \u001b[38;5;241m=\u001b[39m chromadb\u001b[38;5;241m.\u001b[39mEphemeralClient()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.file'"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.storage.chat_store import SimpleChatStore\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from llama_index.readers.file import PDFReader\n",
    "\n",
    "#from llama_hub.youtube_transcript import YoutubeTranscriptReader\n",
    "# create client and a new collection\n",
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.create_collection(\"selfimprovement\")\n",
    "#youtube_collection = chroma_client.create_collection(\"youtube\")\n",
    "\n",
    "# load documents\n",
    "#documents = SimpleDirectoryReader(\"./data/raw/\").load_data()\n",
    "documents = PDFReader().load_data(r\",\\data\\raw\\MF Data - March 2024 - April 2023.pdf\")\n",
    "# set up ChromaVectorStore and load in data\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "#youtube_store = ChromaVectorStore(chroma_collection=youtube_collection)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "#yt_storage_context = StorageContext.from_defaults(vector_store=chat_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context\n",
    ")\n",
    "\n",
    "\n",
    "# Query Data\n",
    "query_engine = index.as_query_engine()\n",
    "response = queryS_engine.query(\"What are the schemes available?\")\n",
    "#display(Markdown(f\"<b>{response}</b>\"))\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from lib.recommendation_system import youtube_recommender\n",
    "def recommend_videos(query):\n",
    "    video_data = youtube_recommender.youtube_searcher(query)\n",
    "    print(video_data)\n",
    "    return \"Sent Videos\"\n",
    "\n",
    "youtube_engine = FunctionTool.from_defaults(\n",
    "    fn=recommend_videos,\n",
    "    name=\"youtube_video_recommender\",\n",
    "    description=\"this tool is used to recommend youtube videos to users from search query\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_videos(\"Robotics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notification(title,body):\n",
    "    print(\"Notification\",title,body)\n",
    "    return \"Sent Notification\"\n",
    "\n",
    "\n",
    "notification_engine = FunctionTool.from_defaults(\n",
    "    fn=notification,\n",
    "    name=\"notification\",\n",
    "    description=\"this tool is used to send notification to user to keep him motivated\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_store = SimpleChatStore()\n",
    "context = \"\"\"Purpose: The primary role of this agent is to assist users by providing mentorship to build a better life\"\"\"\n",
    "\n",
    "chat_memory = ChatMemoryBuffer.from_defaults(\n",
    "    token_limit=3000,\n",
    "    chat_store=chat_store,\n",
    "    chat_store_key=\"user1\",\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    \n",
    "    QueryEngineTool(\n",
    "        query_engine=query_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"Atomic Habits\",\n",
    "            description=\"this gives detailed information on building habits\",\n",
    "        ),\n",
    "    ),\n",
    "\n",
    "    notification_engine\n",
    "]\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "agent = ReActAgent.from_tools(tools, llm=llm, verbose=True, context=context,memor)\n",
    "\n",
    "while (prompt := input(\"Enter a prompt (q to quit): \")) != \"q\":\n",
    "    result = agent.chat(prompt)\n",
    "    print(\"RESULT:\",result)\n",
    "    print(\"HISTORY:\",agent.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_recommender.youtube_searcher(\"Exercise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "dir(BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-readers-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.json import JSONReader\n",
    "document = JSONReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tech = {\n",
    "    \"chat_history\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you remember my name?\",\n",
    "            \"additional_kwargs\": {}\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"I'm sorry, but as an AI assistant, I don't have the capability to remember personal information about individuals unless it has been shared with me in the current conversation. Is there anything else I can assist you with?\",\n",
    "            \"additional_kwargs\": {}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "json.dumps(tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install llama-index-readers-youtube-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import tools\n",
    "tools.recommend_videos(\"Exercising\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from lib import tools\n",
    "\n",
    "tools.send_mail(\"Hi\",\"test mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import recommendation_system\n",
    "yt=recommendation_system.youtube_recommender()\n",
    "yt.recommend_videos(\"study tips for exams\",\"The user is struggling with his exam preparation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.tools import recommend_videos,Video_var\n",
    "recommend_videos(\"study tips for exams\",\"The user is struggling with his exam preparation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video_var.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (0.1.37)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (1.13.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.38)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
      "Installing collected packages: langchain-openai\n",
      "Successfully installed langchain-openai-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing by providing automated testing tools that can help streamline the testing process and identify any bugs or issues in the code. Langsmith can also generate test cases and provide comprehensive test coverage to ensure that the software is functioning correctly. Additionally, Langsmith can help with performance testing, security testing, and regression testing to ensure that the software meets all requirements and specifications.', response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 15, 'total_tokens': 91}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a powerful tool that can greatly assist in testing by enabling automated language translation and localization testing. Here are some ways in which Langsmith can help with testing:\\n\\n1. Automated Translation Testing: Langsmith can automatically translate your application or website content into multiple languages, allowing you to quickly test the translations for accuracy and consistency.\\n\\n2. Localization Testing: Langsmith can simulate different language settings and environments, enabling you to test how your application or website behaves in various languages and locales.\\n\\n3. String Verification: Langsmith can help verify that all strings in your application are properly translated and localized, reducing the risk of language-related bugs and issues.\\n\\n4. Regression Testing: Langsmith can be used to automate regression testing for language-related changes, ensuring that new updates or features do not impact the quality of translations.\\n\\n5. Integration Testing: Langsmith can integrate with your existing testing frameworks and tools, making it easy to incorporate language translation and localization testing into your overall testing strategy.\\n\\nOverall, Langsmith can streamline the testing process, improve testing coverage, and help ensure the quality and consistency of language translations in your application or website.', response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 27, 'total_tokens': 252}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"How can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith is a powerful tool that can greatly assist with testing in several ways:\\n\\n1. Automated Testing: Langsmith can be used to generate automated test scripts for various scenarios, reducing the manual effort required for testing. It can create test cases with different inputs and expected outputs, helping to ensure thorough test coverage.\\n\\n2. Load Testing: Langsmith can simulate a large number of virtual users accessing an application simultaneously, allowing testers to evaluate the performance and scalability of the system under various loads.\\n\\n3. API Testing: Langsmith can be used to automate the testing of APIs by generating test scripts that send requests to API endpoints and validate the responses. This can help ensure that APIs are working correctly and returning the expected results.\\n\\n4. Data-Driven Testing: Langsmith supports data-driven testing, where test cases are executed with different sets of input data. This can help identify potential issues with data handling and processing in the application.\\n\\n5. Regression Testing: Langsmith can generate test scripts that can be run repeatedly to ensure that new code changes do not introduce any regressions or break existing functionality. This can help maintain the quality and stability of the application over time.\\n\\nOverall, Langsmith can streamline the testing process, improve test coverage, and help identify and address issues early in the development cycle, ultimately leading to a more robust and reliable software product.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"How can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.5\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB 325.1 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.1/14.5 MB 465.5 kB/s eta 0:00:32\n",
      "    --------------------------------------- 0.2/14.5 MB 1.2 MB/s eta 0:00:13\n",
      "    --------------------------------------- 0.3/14.5 MB 1.6 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.5 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.4/14.5 MB 1.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.7/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/14.5 MB 1.3 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/14.5 MB 1.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.9/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.9/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.9/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.9/14.5 MB 1.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.0/14.5 MB 1.3 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.2/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.2/14.5 MB 1.4 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.3/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.4/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.4/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.8/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.8/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 1.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.2/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.3/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.3/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.4/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.4/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 2.5/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.5/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.6/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.6/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.7/14.5 MB 1.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.8/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.8/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 2.9/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 2.9/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.0/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.0/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.1/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.1/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 3.2/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.3/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.3/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.3/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.3/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.3/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.5/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.5/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.6/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 3.6/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.0/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 1.3 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 4.3/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 4.3/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.4/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.4/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.5/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.5/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.6/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.6/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 4.7/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.8/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.8/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.9/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 4.9/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.0/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 5.0/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.1/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.2/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.2/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.3/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.3/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.4/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 5.4/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.5/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.5/14.5 MB 1.3 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 5.6/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 5.6/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 5.7/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 5.8/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.8/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.1/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 6.2/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.2/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.4/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 6.5/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.6/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.6/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.7/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.7/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.8/14.5 MB 1.3 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 6.8/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.9/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 6.9/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.0/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.1/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.1/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.2/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 7.2/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.3/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.3/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.4/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.4/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.5/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 7.6/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.6/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.7/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.7/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.8/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.8/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.9/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.9/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.0/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 1.3 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.2/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.2/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 8.3/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.5/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 8.7/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.7/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.8/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.9/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.9/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.0/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.1/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.2/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.2/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.3/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.3/14.5 MB 1.3 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.5/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.5/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.6/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.8/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.9/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 9.9/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.0/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.1/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.1/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.1/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.3/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.3/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.4/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.5/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 1.3 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 10.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 10.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 10.9/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.0/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.0/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.1/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.1/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.2/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.6/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.6/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.7/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.9/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.0/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.0/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.1/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.3/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.3/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.4/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.7/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.7/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.8/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.1/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.2/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.8/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.8/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.1/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help with testing by allowing users to visualize test results.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by allowing developers to create datasets, run tests on LLM applications using these datasets, and easily run custom evaluations (LLM and heuristic based) to score test results. Developers can upload test cases in bulk, create them on the fly, or export them from application traces. LangSmith also provides a comparison view for tracking and diagnosing regressions in test scores across multiple revisions of an application. Additionally, LangSmith offers a playground environment for rapid iteration and experimentation, as well as features for beta testing, capturing feedback, annotating traces, and adding runs to a dataset to refine and improve application performance.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricingSelf-HostingTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content='meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       " Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations\\u200bAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads\\u200bMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='Can LangSmith help test my LLM applications?'),\n",
       "  AIMessage(content='Yes!')],\n",
       " 'input': 'Tell me how',\n",
       " 'context': [Document(page_content='Skip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricingSelf-HostingTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping\\u200bPrototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\\nThe ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging\\u200bWhen developing new LLM applications, we suggest having LangSmith tracing enabled by default.\\nOftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\\nWe provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set\\u200bWhile many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\\nThese test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View\\u200bWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\\nOftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\\nIn order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground\\u200bLangSmith provides a playground environment for rapid iteration and experimentation.\\nThis allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='LangSmith User Guide | 🦜️🛠️ LangSmith', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content='meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.', metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'}),\n",
       "  Document(page_content=\"Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing\\u200bBeta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback\\u200bWhen launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces\\u200bLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset\\u200bAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production\\u200bClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing\\u200bLangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations\\u200bAutomations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads\\u200bMany LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to\", metadata={'source': 'https://docs.smith.langchain.com/user_guide', 'title': 'LangSmith User Guide | 🦜️🛠️ LangSmith', 'description': 'LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.', 'language': 'en'})],\n",
       " 'answer': 'LangSmith can help test your LLM applications by providing features such as:\\n\\n1. Prototyping: Allows for quick experimentation between prompts, model types, and retrieval strategies.\\n2. Debugging: Enables debugging with clear visibility and information at each step of an LLM sequence.\\n3. Initial Test Set: Supports creating datasets for running tests on LLM applications.\\n4. Comparison View: Helps track and diagnose regressions in test scores across multiple revisions of your application.\\n5. Playground: Provides a rapid iteration and experimentation environment for testing different prompts and models.\\n6. Beta Testing: Allows for collecting data on how your LLM applications perform in real-world scenarios.\\n7. Capturing Feedback: Enables gathering human feedback on the responses your application produces.\\n8. Monitoring and A/B Testing: Provides monitoring charts and A/B testing capabilities to track key metrics and make comparisons.\\n9. Automations: Allows for automating actions on traces in near real-time, such as scoring traces or sending them to datasets.\\n\\nThese features make it easier to test and improve the performance of your LLM applications using LangSmith.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240402-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240402-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240402\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (0.1.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (0.1.37)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (1.13.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.38)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\prasannan-robots\\desktop\\mentor\\mentor-server\\depenv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# You need to set OPENAI_API_KEY environment variable or pass it as argument `openai_api_key`.\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'how can LangSmith help with testing'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mSkip to main content🦜️🛠️ LangSmith DocsLangChain Python DocsLangChain JS/TS DocsLangSmith API DocsSearchGo to AppLangSmithUser GuideSetupPricingSelf-HostingTracingEvaluationProduction Monitoring & AutomationsPrompt HubProxyCookbookUser GuideOn this pageLangSmith User GuideLangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.Prototyping​Prototyping LLM applications often involves quick experimentation between prompts, model types, retrieval strategy and other parameters.\n",
      "The ability to rapidly understand how the model is performing — and debug where it is failing — is incredibly important for this phase.Debugging​When developing new LLM applications, we suggest having LangSmith tracing enabled by default.\n",
      "Oftentimes, it isn’t necessary to look at every single trace. However, when things go wrong (an unexpected end result, infinite agent loop, slower than expected execution, higher than expected token usage), it’s extremely helpful to debug by looking through the application traces. LangSmith gives clear visibility and debugging information at each step of an LLM sequence, making it much easier to identify and root-cause issues.\n",
      "We provide native rendering of chat messages, functions, and retrieve documents.Initial Test Set​While many developers still ship an initial version of their application based on “vibe checks”, we’ve seen an increasing number of engineering teams start to adopt a more test driven approach. LangSmith allows developers to create datasets, which are collections of inputs and reference outputs, and use these to run tests on their LLM applications.\n",
      "These test cases can be uploaded in bulk, created on the fly, or exported from application traces. LangSmith also makes it easy to run custom evaluations (both LLM and heuristic based) to score test results.Comparison View​When prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\n",
      "Oftentimes, changes in the prompt, retrieval strategy, or model choice can have huge implications in responses produced by your application.\n",
      "In order to get a sense for which variant is performing better, it’s useful to be able to view results for different configurations on the same datapoints side-by-side. We’ve invested heavily in a user-friendly comparison view for test runs to track and diagnose regressions in test scores across multiple revisions of your application.Playground​LangSmith provides a playground environment for rapid iteration and experimentation.\n",
      "This allows you to quickly test out different prompts and models. You can open the playground from any prompt or model run in your trace.\n",
      "\n",
      "Every playground run is logged in the system and can be used to create test cases or compare with other runs.Beta Testing​Beta testing allows developers to collect more data on how their LLM applications are performing in real-world scenarios. In this phase, it’s important to develop an understanding for the types of inputs the app is performing well or poorly on and how exactly it’s breaking down in those cases. Both feedback collection and run annotation are critical for this workflow. This will help in curation of test cases that can help track regressions/improvements and development of automatic evaluations.Capturing Feedback​When launching your application to an initial set of users, it’s important to gather human feedback on the responses it’s producing. This helps draw attention to the most interesting runs and highlight edge cases that are causing problematic responses. LangSmith allows you to attach feedback scores to logged traces (oftentimes, this is hooked up to a feedback button in your app), then filter on traces that have a specific feedback tag and score. A common workflow is to filter on traces that receive a poor user feedback score, then drill down into problematic points using the detailed trace view.Annotating Traces​LangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Annotators can be PMs, engineers, or even subject matter experts. This allows users to catch regressions across important evaluation criteria.Adding Runs to a Dataset​As your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. LangSmith enables you to add runs as examples to datasets (from both the project page and within an annotation queue), expanding your test coverage on real-world scenarios. This is a key benefit in having your logging system and your evaluation/testing system in the same platform.Production​Closely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production.However, especially at the production stage, it’s crucial to get a high-level overview of application performance with respect to latency, cost, and feedback scores. This ensures that it's delivering desirable results at scale.Online evaluations and automations allow you to process and score production traces in near real-time.Additionally, threads provide a seamless way to group traces from a single conversation, making it easier to track the performance of your application across multiple turns.Monitoring and A/B Testing​LangSmith provides monitoring charts that allow you to track key metrics over time. You can expand to view metrics for a given period and drill down into a specific data point to get a trace table for that time period — this is especially handy for debugging production issues.LangSmith also allows for tag and metadata grouping, which allows users to mark different versions of their applications with different identifiers and view how they are performing side-by-side within each chart. This is helpful for A/B testing changes in prompt, model, or retrieval strategy.Automations​Automations are a powerful feature in LangSmith that allow you to perform actions on traces in near real-time. This can be used to automatically score traces, send them to annotation queues, or send them to datasets.To define an automation, simply provide a filter condition, a sampling rate, and an action to perform. Automations are particularly helpful for processing traces at production scale.Threads​Many LLM applications are multi-turn, meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to\n",
      "\n",
      "LangSmith User Guide | 🦜️🛠️ LangSmith\n",
      "\n",
      "meaning that they involve a series of interactions between the user and the application. LangSmith provides a threads view that groups traces from a single conversation together, making it easier to track the performance of and annotate your application across multiple turns.Was this page helpful?PreviousLangSmithNextSetupPrototypingBeta TestingProductionCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogCopyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mLangSmith can help with testing in various ways throughout the application development lifecycle. Here are some key ways LangSmith supports testing:\n",
      "\n",
      "1. Prototyping: LangSmith allows for quick experimentation between prompts, model types, retrieval strategies, and other parameters to understand how the model is performing during the prototyping phase.\n",
      "\n",
      "2. Debugging: LangSmith provides tracing capabilities that enable developers to debug issues by looking through application traces, providing clear visibility and debugging information at each step of an LLM sequence.\n",
      "\n",
      "3. Initial Test Set: Developers can create datasets of inputs and reference outputs to run tests on LLM applications, facilitating a more test-driven approach to application development.\n",
      "\n",
      "4. Comparison View: LangSmith offers a comparison view for test runs, allowing developers to track and diagnose regressions in test scores across multiple revisions of their application.\n",
      "\n",
      "5. Playground: LangSmith provides a playground environment for rapid iteration and experimentation with different prompts and models, logging each run for further analysis.\n",
      "\n",
      "6. Beta Testing: Developers can collect data on how their LLM applications perform in real-world scenarios during beta testing, gathering feedback and annotations to track regressions and improvements.\n",
      "\n",
      "7. Production Monitoring: LangSmith enables monitoring of key metrics, A/B testing of changes, and automations for processing traces in near real-time to ensure application performance at scale.\n",
      "\n",
      "Overall, LangSmith's features such as tracing, testing capabilities, comparison views, and monitoring tools make it a valuable platform for testing and optimizing LLM applications throughout their development and deployment stages.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how can langsmith help with testing?',\n",
       " 'output': \"LangSmith can help with testing in various ways throughout the application development lifecycle. Here are some key ways LangSmith supports testing:\\n\\n1. Prototyping: LangSmith allows for quick experimentation between prompts, model types, retrieval strategies, and other parameters to understand how the model is performing during the prototyping phase.\\n\\n2. Debugging: LangSmith provides tracing capabilities that enable developers to debug issues by looking through application traces, providing clear visibility and debugging information at each step of an LLM sequence.\\n\\n3. Initial Test Set: Developers can create datasets of inputs and reference outputs to run tests on LLM applications, facilitating a more test-driven approach to application development.\\n\\n4. Comparison View: LangSmith offers a comparison view for test runs, allowing developers to track and diagnose regressions in test scores across multiple revisions of their application.\\n\\n5. Playground: LangSmith provides a playground environment for rapid iteration and experimentation with different prompts and models, logging each run for further analysis.\\n\\n6. Beta Testing: Developers can collect data on how their LLM applications perform in real-world scenarios during beta testing, gathering feedback and annotations to track regressions and improvements.\\n\\n7. Production Monitoring: LangSmith enables monitoring of key metrics, A/B testing of changes, and automations for processing traces in near real-time to ensure application performance at scale.\\n\\nOverall, LangSmith's features such as tracing, testing capabilities, comparison views, and monitoring tools make it a valuable platform for testing and optimizing LLM applications throughout their development and deployment stages.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
